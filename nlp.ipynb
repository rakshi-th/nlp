{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddEJvV_K_aOh",
        "outputId": "05156bce-5991-4365-ddb2-c4dec8b89b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams:\n",
            "<FreqDist with 38 samples and 56 outcomes>\n",
            "\n",
            "Bigrams:\n",
            "<FreqDist with 54 samples and 55 outcomes>\n",
            "\n",
            "Trigrams:\n",
            "<FreqDist with 54 samples and 54 outcomes>\n",
            "\n",
            "Bigram Probabilities:\n",
            "P(language|natural) = 1.0000\n",
            "P(processing|language) = 0.3333\n",
            "P(.|language) = 0.3333\n",
            "P(in|language) = 0.3333\n",
            "P((|processing) = 1.0000\n",
            "P(nlp|() = 0.5000\n",
            "P(ai|() = 0.5000\n",
            "P()|nlp) = 0.5000\n",
            "P(is|nlp) = 0.5000\n",
            "P(is|)) = 0.5000\n",
            "P(that|)) = 0.5000\n",
            "P(a|is) = 0.3333\n",
            "P(to|is) = 0.3333\n",
            "P(both|is) = 0.3333\n",
            "P(field|a) = 0.5000\n",
            "P(way|a) = 0.5000\n",
            "P(of|field) = 1.0000\n",
            "P(artificial|of) = 0.5000\n",
            "P(nlp|of) = 0.5000\n",
            "P(intelligence|artificial) = 1.0000\n",
            "P((|intelligence) = 1.0000\n",
            "P()|ai) = 1.0000\n",
            "P(focuses|that) = 0.5000\n",
            "P(is|that) = 0.5000\n",
            "P(on|focuses) = 1.0000\n",
            "P(the|on) = 1.0000\n",
            "P(interaction|the) = 0.5000\n",
            "P(ultimate|the) = 0.5000\n",
            "P(between|interaction) = 1.0000\n",
            "P(computers|between) = 1.0000\n",
            "P(and|computers) = 0.5000\n",
            "P(to|computers) = 0.5000\n",
            "P(humans|and) = 0.3333\n",
            "P(generate|and) = 0.3333\n",
            "P(useful|and) = 0.3333\n",
            "P(through|humans) = 1.0000\n",
            "P(natural|through) = 1.0000\n",
            "P(the|.) = 1.0000\n",
            "P(objective|ultimate) = 1.0000\n",
            "P(of|objective) = 1.0000\n",
            "P(enable|to) = 0.5000\n",
            "P(understand|to) = 0.5000\n",
            "P(computers|enable) = 1.0000\n",
            "P(,|understand) = 1.0000\n",
            "P(interpret|,) = 0.5000\n",
            "P(and|,) = 0.5000\n",
            "P(,|interpret) = 1.0000\n",
            "P(human|generate) = 1.0000\n",
            "P(language|human) = 1.0000\n",
            "P(a|in) = 1.0000\n",
            "P(that|way) = 1.0000\n",
            "P(meaningful|both) = 1.0000\n",
            "P(and|meaningful) = 1.0000\n",
            "P(.|useful) = 1.0000\n",
            "\n",
            "Next word prediction for 'the': interaction\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize, FreqDist\n",
        "from nltk.util import bigrams, trigrams\n",
        "from nltk.probability import FreqDist, ConditionalFreqDist\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "corpus = \"\"\"\n",
        "Natural language processing (NLP) is a field of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "tokens = word_tokenize(corpus.lower())\n",
        "\n",
        "unigrams = list(nltk.ngrams(tokens, 1))\n",
        "unigram_freq = FreqDist(unigrams)\n",
        "\n",
        "\n",
        "bigrams_list = list(bigrams(tokens))\n",
        "bigram_freq = FreqDist(bigrams_list)\n",
        "\n",
        "\n",
        "trigrams_list = list(trigrams(tokens))\n",
        "trigram_freq = FreqDist(trigrams_list)\n",
        "\n",
        "bigram_probabilities = ConditionalFreqDist((w1, w2) for w1, w2 in bigrams_list)\n",
        "for w1 in bigram_probabilities:\n",
        "    total_count = sum(bigram_probabilities[w1].values())\n",
        "    for w2 in bigram_probabilities[w1]:\n",
        "        bigram_probabilities[w1][w2] /= total_count\n",
        "\n",
        "\n",
        "def predict_next_word(word, bigram_probabilities):\n",
        "    if word in bigram_probabilities:\n",
        "        return bigram_probabilities[word].max()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"Unigrams:\")\n",
        "print(unigram_freq)\n",
        "\n",
        "print(\"\\nBigrams:\")\n",
        "print(bigram_freq)\n",
        "\n",
        "print(\"\\nTrigrams:\")\n",
        "print(trigram_freq)\n",
        "\n",
        "print(\"\\nBigram Probabilities:\")\n",
        "for w1 in bigram_probabilities:\n",
        "    for w2 in bigram_probabilities[w1]:\n",
        "        print(f\"P({w2}|{w1}) = {bigram_probabilities[w1][w2]:.4f}\")\n",
        "\n",
        "\n",
        "word = 'the'\n",
        "next_word = predict_next_word(word, bigram_probabilities)\n",
        "print(f\"\\nNext word prediction for '{word}': {next_word}\")"
      ]
    }
  ]
}